# Dot-Product Attention

[A2-Nets: Double Attention Networks](https://arxiv.org/abs/1810.11579) (with **linear** computational complexity and memory consumption of [Non-local Neural Networks](https://arxiv.org/abs/1711.07971))

